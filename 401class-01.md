# Code 401 Class 01 Reading Notes

## [Pain vs. Suffering](https://codefellows.github.io/code-401-python-guide/curriculum/class-01/notes/pain_suffering)

Wow, what a read. It definitely confirms what I have been thinking how this course is going to impact me. I'm an fitness enthusiast and can relate fitness growth to mind growth relatively easy. Having a 'Why', as the article states, is a **MUST**. You need to remind yourself and others around you *why* you are doing this and repeat it as often as it takes.

What helped me out a lot during the 'pain', and out of the 'suffering', is asking for help and looking at it from multiple points of view. I'm not just asking one person, I am asking 2 to 3 and also looking things up just to make sure the problem I have is taking shape.

Let's build some callouses!

------

## [Beginners Guid to Big O](https://rob-bell.net/2009/06/a-beginners-guide-to-big-o-notation)

1. **$O(1)$** describes an algorithm that will always execute in the same time (or space) regardless of the size of the input data set.
2. **$O(N)$** describes an algorithm whose performance will grow linearly and in direct proportion to the size of the input data set.
3. **$O(N^2)$** represents an algorithm whose performance is directly proportional to the square of the size of the input data set. This is common for algorithms that involve nested iterations over the data set.
4. **$O(2^N)$** denotes an algorithm whose growth doubles with each addition to the input data set. Fibonacci is a great examples.
5. **Logarithms** It works by selecting the middle element of the data set, essentially the median, and compares it against a target value. If the values match, it will return a success. If the target value is higher than the value of the probe element, it will take the upper half of the data set and perform the same operation against it. If the target value is lower than the value of the probe element, it will perform the operation against the lower half. This is often described as **$O(log N)$**.

A grasp of Big O is an important tool when dealing with algorithms that need to operate at scale, allowing you to make the correct choices and acknowledge trade-offs when working with different data sets.

## Things I want to know more about

[<---BACK](README.md)
